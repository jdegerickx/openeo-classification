{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73bf537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import landuse_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1513ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = openeo.connect(\"https://openeo.vito.be\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46deb82a",
   "metadata": {},
   "source": [
    "#### Target data \n",
    "LUCAS, 2018 (land use cover)\n",
    "\n",
    "#### Input data\n",
    "From S2: calculation of 7 indices (NDVI, NDMI, NDGI, ANIR, NDRE1, NDRE2, NDRE5) and keeping 2 bands (B06, B12)\n",
    "From S1: VV, VH and VV/VH\n",
    "For all of these, 10 features: p25, p50, p75, sd and 6 t-steps, with flexible range\n",
    "\n",
    "#### Model\n",
    "Random Forest, trained using custom hyperparameter, 70/30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b82cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## User options\n",
    "## TODO: @Bart Convert this into HTML widgets!\n",
    "\n",
    "\n",
    "## % of test data\n",
    "train_test_split = 0.3\n",
    "\n",
    "algorithm = \"RandomForest\"\n",
    "\n",
    "hyperparams = {\n",
    "    num_trees: ##,\n",
    "    mtry: ##\n",
    "}\n",
    "\n",
    "## USE ONLY S1, ONLY S2 or both\n",
    "feature_raster = \"both\" # s1, s2 or both\n",
    "\n",
    "## Area of interest\n",
    "aoi = gpd.read_file('lucas/test_aoi.geojson')\n",
    "\n",
    "## Stratification layer\n",
    "strat_layer = gpd.read_file(\"lucas/test_stratification.geojson\") #None or a geojson\n",
    "\n",
    "## Easy lookup to see what classes represent\n",
    "print(lookup_lucas[\"C10\"])\n",
    "\n",
    "## Custom legend\n",
    "final_labels = {\n",
    "    \"Broadleaved woodland\": [\"C10\"],\n",
    "    \"Coniferous woodland\": [\"C20\"],\n",
    "    \"Mixed woodland\": [\"C30\"],\n",
    "    \"Shrubland\": [\"D00\", \"D10\", \"D20\"],\n",
    "    \"Grassland\": [\"E00\", \"E10\", \"E20\", \"E30\"],\n",
    "    \"Cropland\": [\"B00\", \"B10\", \"B20\", \"B30\",\"B40\", \"B50\", \"B70\", \"B80\"],\n",
    "    \"Bare land\": [\"F00\", \"F10\", \"F20\", \"F40\"],\n",
    "    \"Lichens and moss\": [\"F30\"],\n",
    "    \"Built-up\": [\"A00\", \"A10\", \"A20\", \"A30\"],\n",
    "    \"Inland water\": [\"G10\", \"G20\", \"G30\"],\n",
    "    \"Sea and ocean\": [\"G40\"],\n",
    "    \"Glaciers and permanent snow\": [\"G50\"],\n",
    "    \"Wetlands\": [\"H00\", \"H10\", \"H20\"]\n",
    "}\n",
    "\n",
    "## Cleaning & filtering operations on dataset\n",
    "include_mixed_pixels = False\n",
    "max_nr_samples = None\n",
    "start_date = date(year,3,15)\n",
    "end_date = date(year,10,31)\n",
    "stepsize_s2 = 10\n",
    "stepsize_s1 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0eecdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: @Bart use extended polygon LUCAS set https://essd.copernicus.org/articles/13/1119/2021/ and then extract points\n",
    "data = gpd.read_file(\"https://artifactory.vgt.vito.be/auxdata-public/openeo/lucas.gpkg\",mask=aoi)\n",
    "\n",
    "if data.empty:\n",
    "    raise ValueError(\"Your masked area is located outside of Europe or so small that no training data can be found within it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a5efbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: @Bart only keep label + geometry and make sure label matches general labels ([0:2] from label)\n",
    "y = data[[\"LC1\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2d75d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if strat_layer is None:\n",
    "    strat_layer = aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a4d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stratum in strat_layer.iterfeatures():\n",
    "    final_training_data = gpd.clip(data, gpd.GeoDataFrame(stratum))\n",
    "    ## TODO: @Bart load_features spatial_extents toevoegen\n",
    "    features, feature_list = load_features(feature_raster, stratum, start_date, end_date, stepsize_s2, stepsize_s1)\n",
    "\n",
    "    ## TODO: @Bart testen tot aan hier!\n",
    "    X = features.aggregate_spatial(geometries=y[\"geometry\"], reducer=mean)\n",
    "    ## dit testen tot hier\n",
    "        \n",
    "    ## TODO ? load_vectorcube, wellicht niet nodig gezien we alleen hoeven clippen naar een spatial extent. Load_files?\n",
    "#     target = connection.load_vectorcube(\"x.geojson\")\n",
    "    \n",
    "    ## TODO: fit_class_random_forest werkend krijgen voor X en y als inputs\n",
    "    ml_model = con.fit_class_random_forest(predictors=X, target=y, training=100, **hyperparams)\n",
    "    ml_model = ml_model.save_ml_model().start_and_wait().get_result()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final inference: 2-3 tiles, 2-3 different scenarios\n",
    "for stratum in strat_layer.iterfeatures():\n",
    "    con.load_ml_model('batch_job_id')\n",
    "    features, feature_list = load_features(feature_raster, stratum, start_date, end_date, stepsize_s2, stepsize_s1)\n",
    "\n",
    "    def predict_rf(x: ProcessBuilder):\n",
    "        ## TODO: bedenken hoe dit eruit gaat zien\n",
    "        return x.predict_random_forest(features)\n",
    "\n",
    "    y_pred = datacube.reduce_dimension(dimension=\"bands\", process=predict_rf)\n",
    "\n",
    "## Daarna verschillende predicties door verschillende strata weer terug mergen in 1 beeld ?\n",
    "    \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "prec, rec, fscore, sup = precision_recall_fscore_support(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nice to have: custom rules toevoegen\n",
    "#     ## Applying custom rules to the classification\n",
    "#     def rule_glaciers(x: ProcessBuilder):\n",
    "#         if x.is_nodata():\n",
    "#             return array_create(data=[65534]*120)\n",
    "#         return x    \n",
    "#     datacube.apply_dimension(dimension=\"t\", process=rule_glaciers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
