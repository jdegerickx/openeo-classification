{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bf537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from landuse_classification import *\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1513ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = openeo.connect(\"https://openeo-dev.vito.be\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46deb82a",
   "metadata": {},
   "source": [
    "#### Target data \n",
    "LUCAS, 2018 (land use cover)\n",
    "\n",
    "#### Input data\n",
    "From S2: calculation of 7 indices (NDVI, NDMI, NDGI, ANIR, NDRE1, NDRE2, NDRE5) and keeping 2 bands (B06, B12)\n",
    "From S1: VV, VH and VV/VH\n",
    "For all of these, 10 features: p25, p50, p75, sd and 6 t-steps, with flexible range\n",
    "\n",
    "#### Model\n",
    "Random Forest, trained using custom hyperparameter, 70/30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b82cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## User options\n",
    "## TODO: @Bart Convert this into HTML widgets!\n",
    "\n",
    "\n",
    "## % of test data\n",
    "train_test_split = 0.3\n",
    "\n",
    "algorithm = \"RandomForest\"\n",
    "\n",
    "hyperparams = {\n",
    "    \"num_trees\": 250,\n",
    "    \"mtry\": 3\n",
    "}\n",
    "\n",
    "## USE ONLY S1, ONLY S2 or both\n",
    "feature_raster = \"both\" # s1, s2 or both\n",
    "\n",
    "## Area of interest\n",
    "aoi = gpd.read_file('lucas/test_aoi.geojson')\n",
    "\n",
    "## Stratification layer\n",
    "strat_layer = gpd.read_file(\"lucas/test_stratification.geojson\") #None or a geojson\n",
    "\n",
    "## Easy lookup to see what classes represent\n",
    "# print(lookup_lucas[\"C10\"])\n",
    "\n",
    "## Custom legend\n",
    "final_labels = {\n",
    "    \"Broadleaved woodland\": [\"C10\"],\n",
    "    \"Coniferous woodland\": [\"C20\"],\n",
    "    \"Mixed woodland\": [\"C30\"],\n",
    "    \"Shrubland\": [\"D00\", \"D10\", \"D20\"],\n",
    "    \"Grassland\": [\"E00\", \"E10\", \"E20\", \"E30\"],\n",
    "    \"Cropland\": [\"B00\", \"B10\", \"B20\", \"B30\",\"B40\", \"B50\", \"B70\", \"B80\"],\n",
    "    \"Bare land\": [\"F00\", \"F10\", \"F20\", \"F40\"],\n",
    "    \"Lichens and moss\": [\"F30\"],\n",
    "    \"Built-up\": [\"A00\", \"A10\", \"A20\", \"A30\"],\n",
    "    \"Inland water\": [\"G10\", \"G20\", \"G30\"],\n",
    "    \"Sea and ocean\": [\"G40\"],\n",
    "    \"Glaciers and permanent snow\": [\"G50\"],\n",
    "    \"Wetlands\": [\"H00\", \"H10\", \"H20\"]\n",
    "}\n",
    "\n",
    "## Cleaning & filtering operations on dataset\n",
    "include_mixed_pixels = False\n",
    "max_nr_samples = None\n",
    "start_date = date(2018,3,15)\n",
    "end_date = date(2018,10,31)\n",
    "stepsize_s2 = 10\n",
    "stepsize_s1 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0eecdb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## TODO: @Bart use extended polygon LUCAS set https://essd.copernicus.org/articles/13/1119/2021/ and then extract points\n",
    "data = gpd.read_file(\"https://artifactory.vgt.vito.be/auxdata-public/openeo/lucas.gpkg\",mask=aoi)\n",
    "\n",
    "if data.empty:\n",
    "    raise ValueError(\"Your masked area is located outside of Europe or so small that no training data can be found within it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a5efbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-7843e3782b1e>:3: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  y2 = y.buffer(0.0001)\n"
     ]
    }
   ],
   "source": [
    "## TODO: @Bart only keep label + geometry and make sure label matches general labels ([0:2] from label)\n",
    "y = data[[\"LC1\", \"geometry\"]]\n",
    "y2 = y.buffer(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fedd8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = y2.to_json()\n",
    "y4 = y.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2d75d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if strat_layer is None:\n",
    "    strat_layer = aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ecd282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lc_features(feature_raster, aoi, start_date, end_date, stepsize_s2=10, stepsize_s1=12):\n",
    "    provider = \"terrascope\"\n",
    "    \n",
    "    idx_dekad = sentinel2_features(start_date, end_date, connection, provider, processing_opts={}, sampling=True, stepsize=stepsize_s2)\n",
    "    idx_features = compute_statistics(idx_dekad, start_date, end_date, stepsize=stepsize_s2)\n",
    "\n",
    "    s1_dekad = sentinel1_features(start_date, end_date, connection, provider, processing_opts={}, orbitDirection=\"ASCENDING\", sampling=True, stepsize=stepsize_s1)\n",
    "    s1_dekad = s1_dekad.resample_cube_spatial(idx_dekad)\n",
    "    s1_features = compute_statistics(s1_dekad, start_date, end_date, stepsize=stepsize_s1)\n",
    "\n",
    "    features = idx_features.merge_cubes(s1_features)\n",
    "\n",
    "    if feature_raster == \"s1\":\n",
    "        return s1_features, features.metadata.band_names\n",
    "    elif feature_raster == \"s2\":\n",
    "        return idx_features, idx_features.metadata.band_names\n",
    "    else:\n",
    "        return features, features.metadata.band_names\n",
    "    \n",
    "from openeo_classification.connection import connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3a4d9ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n",
      "Authenticated using refresh token.\n",
      "0:00:00 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': send 'start'\n",
      "0:00:34 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': queued (progress N/A)\n",
      "0:00:41 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': queued (progress N/A)\n",
      "0:00:48 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': queued (progress N/A)\n",
      "0:00:56 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': queued (progress N/A)\n",
      "0:01:07 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': queued (progress N/A)\n",
      "0:01:20 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': queued (progress N/A)\n",
      "0:01:37 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': queued (progress N/A)\n",
      "0:01:57 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': queued (progress N/A)\n",
      "0:02:22 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': queued (progress N/A)\n",
      "0:02:53 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': running (progress N/A)\n",
      "0:03:31 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': running (progress N/A)\n",
      "0:04:19 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': running (progress N/A)\n",
      "0:05:20 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': running (progress N/A)\n",
      "0:06:21 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': running (progress N/A)\n",
      "0:07:22 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': running (progress N/A)\n",
      "0:08:25 Job 'b6593759-c7f1-4773-a487-9f69bb4636bb': finished (progress N/A)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('aggspatialtest_traditional/openEO_0.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_1.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_10.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_11.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_12.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_13.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_14.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_15.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_16.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_17.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_18.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_19.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_2.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_20.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_21.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_22.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_23.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_24.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_25.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_26.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_27.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_28.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_29.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_3.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_30.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_31.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_32.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_33.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_34.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_35.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_36.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_37.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_38.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_39.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_4.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_40.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_41.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_42.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_43.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_44.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_45.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_46.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_47.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_48.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_49.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_5.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_50.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_51.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_52.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_53.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_54.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_55.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_56.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_57.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_58.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_59.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_6.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_60.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_61.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_62.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_63.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_64.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_65.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_7.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_8.nc'),\n",
       " WindowsPath('aggspatialtest_traditional/openEO_9.nc')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for stratum in strat_layer.iterfeatures():\n",
    "# final_training_data = gpd.clip(data, gpd.GeoDataFrame(stratum))\n",
    "    ## TODO: @Bart load_features spatial_extents toevoegen\n",
    "features, feature_list = load_lc_features(feature_raster, y, start_date, end_date, stepsize_s2, stepsize_s1)\n",
    "import json\n",
    "    ## TODO: @Bart testen tot aan hier!\n",
    "# X = features.aggregate_spatial(geometries=eval(y4), reducer=\"mean\")\n",
    "# X.download(\"aggspatialtest.csv\", format=\"CSV\")\n",
    "sampled_features = features.filter_spatial(json.loads(y3))\n",
    "job = sampled_features.execute_batch(\n",
    "        title=\"Test aggregate spatial\",\n",
    "        description=\"Test aggregate spatial\",\n",
    "        out_format=\"netCDF\",\n",
    "        sample_by_feature=True)\n",
    "results = job.get_results()\n",
    "results.download_files(\"aggspatialtest_traditional\")\n",
    "    ## dit testen tot hier\n",
    "\n",
    "# X_fin = X.execute()\n",
    "# from openeo.rest.conversions import timeseries_json_to_pandas\n",
    "# X_finfin = timeseries_json_to_pandas(timeseries)\n",
    "# print(X_finfin)\n",
    "\n",
    "    ## TODO ? load_vectorcube, wellicht niet nodig gezien we alleen hoeven clippen naar een spatial extent. Load_files?\n",
    "#     target = connection.load_vectorcube(\"x.geojson\")\n",
    "    \n",
    "    ## TODO: fit_class_random_forest werkend krijgen voor X en y als inputs\n",
    "#     ml_model = con.fit_class_random_forest(predictors=X, target=y, training=100, **hyperparams)\n",
    "#     ml_model = ml_model.save_ml_model().start_and_wait().get_result()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final inference: 2-3 tiles, 2-3 different scenarios\n",
    "for stratum in strat_layer.iterfeatures():\n",
    "    con.load_ml_model('batch_job_id')\n",
    "    features, feature_list = load_features(feature_raster, stratum, start_date, end_date, stepsize_s2, stepsize_s1)\n",
    "\n",
    "    def predict_rf(x: ProcessBuilder):\n",
    "        ## TODO: bedenken hoe dit eruit gaat zien\n",
    "        return x.predict_random_forest(features)\n",
    "\n",
    "    y_pred = datacube.reduce_dimension(dimension=\"bands\", process=predict_rf)\n",
    "\n",
    "## Daarna verschillende predicties door verschillende strata weer terug mergen in 1 beeld ?\n",
    "    \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "prec, rec, fscore, sup = precision_recall_fscore_support(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nice to have: custom rules toevoegen\n",
    "#     ## Applying custom rules to the classification\n",
    "#     def rule_glaciers(x: ProcessBuilder):\n",
    "#         if x.is_nodata():\n",
    "#             return array_create(data=[65534]*120)\n",
    "#         return x    \n",
    "#     datacube.apply_dimension(dimension=\"t\", process=rule_glaciers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
